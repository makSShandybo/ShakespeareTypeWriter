{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":173429532,"sourceType":"kernelVersion"},{"sourceId":267313,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":228753,"modelId":250508}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport torch\nimport nltk\nimport einops\nimport numpy as np\nimport keras.utils as ku \ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nfrom datasets import load_dataset\nimport subprocess\n\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')\n\nfrom nltk.corpus import wordnet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:15:30.236876Z","iopub.execute_input":"2025-02-25T13:15:30.237193Z","iopub.status.idle":"2025-02-25T13:15:48.533705Z","shell.execute_reply.started":"2025-02-25T13:15:30.237166Z","shell.execute_reply":"2025-02-25T13:15:48.533025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = nltk.WordPunctTokenizer()\nlemmatizer = nltk.WordNetLemmatizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:15:48.534455Z","iopub.execute_input":"2025-02-25T13:15:48.535045Z","iopub.status.idle":"2025-02-25T13:15:48.538449Z","shell.execute_reply.started":"2025-02-25T13:15:48.535021Z","shell.execute_reply":"2025-02-25T13:15:48.537661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/shakespeare-nlp-analysis-data-engineering/shakespeare_plays.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:22.493685Z","iopub.execute_input":"2025-02-25T13:17:22.494151Z","iopub.status.idle":"2025-02-25T13:17:22.844322Z","shell.execute_reply.started":"2025-02-25T13:17:22.494110Z","shell.execute_reply":"2025-02-25T13:17:22.843367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_text = []\nfor sentence in df['text']:\n    all_text.append(sentence.lower())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:22.845642Z","iopub.execute_input":"2025-02-25T13:17:22.845991Z","iopub.status.idle":"2025-02-25T13:17:22.890955Z","shell.execute_reply.started":"2025-02-25T13:17:22.845958Z","shell.execute_reply":"2025-02-25T13:17:22.890124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_pipeline(sentence):\n    tokens= tokenizer.tokenize(sentence)\n    return [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:22.892768Z","iopub.execute_input":"2025-02-25T13:17:22.893104Z","iopub.status.idle":"2025-02-25T13:17:22.897641Z","shell.execute_reply.started":"2025-02-25T13:17:22.893074Z","shell.execute_reply":"2025-02-25T13:17:22.896764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_tokenized_text = ([tokenize_pipeline(sentence) for sentence in all_text])\nall_tokenized_words = set(word for sentence in all_tokenized_text for word in sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:22.956229Z","iopub.execute_input":"2025-02-25T13:17:22.956440Z","iopub.status.idle":"2025-02-25T13:17:27.460695Z","shell.execute_reply.started":"2025-02-25T13:17:22.956422Z","shell.execute_reply":"2025-02-25T13:17:27.459760Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(all_tokenized_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:27.461830Z","iopub.execute_input":"2025-02-25T13:17:27.462144Z","iopub.status.idle":"2025-02-25T13:17:27.467549Z","shell.execute_reply.started":"2025-02-25T13:17:27.462116Z","shell.execute_reply":"2025-02-25T13:17:27.466805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"words_to_ids = {word: idx + 4 for idx, word in enumerate(all_tokenized_words)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:27.469227Z","iopub.execute_input":"2025-02-25T13:17:27.469513Z","iopub.status.idle":"2025-02-25T13:17:27.492418Z","shell.execute_reply.started":"2025-02-25T13:17:27.469486Z","shell.execute_reply":"2025-02-25T13:17:27.491657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(words_to_ids) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:27.493452Z","iopub.execute_input":"2025-02-25T13:17:27.493728Z","iopub.status.idle":"2025-02-25T13:17:27.509326Z","shell.execute_reply.started":"2025-02-25T13:17:27.493700Z","shell.execute_reply":"2025-02-25T13:17:27.508560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_sequence_len = max([len(x) for x in all_tokenized_text])\nmax_sequence_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:27.510201Z","iopub.execute_input":"2025-02-25T13:17:27.510462Z","iopub.status.idle":"2025-02-25T13:17:27.544059Z","shell.execute_reply.started":"2025-02-25T13:17:27.510437Z","shell.execute_reply":"2025-02-25T13:17:27.543146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\ndataset = {'Text': all_tokenized_text}\ndataset = Dataset.from_dict(dataset)\ndataset = dataset.train_test_split(test_size=0.05)\ntrain_dataset, validation_dataset = dataset['train'],dataset['test']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:27.544955Z","iopub.execute_input":"2025-02-25T13:17:27.545240Z","iopub.status.idle":"2025-02-25T13:17:27.811872Z","shell.execute_reply.started":"2025-02-25T13:17:27.545211Z","shell.execute_reply":"2025-02-25T13:17:27.810982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ShakespeareDataset(torch.utils.data.Dataset):\n    def __init__(self, words_to_ids, dataset, max_len=19):\n        self.words_to_ids = words_to_ids\n\n\n        def convert_words_to_ids(example):\n            return {'ids': [self.words_to_ids[token] for token in example['Text']]}\n            \n        self.dataset = dataset.map(convert_words_to_ids)\n        self.max_len=max_len\n        \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, index):\n        examplede = self.dataset[index]\n        examplede = examplede['ids']\n        sentence = [1] + examplede+ [2]\n        if len(sentence)< self.max_len:\n            sentence +=[0 for _ in range(self.max_len-len(sentence))] \n\n        return torch.tensor(sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:27.813027Z","iopub.execute_input":"2025-02-25T13:17:27.813267Z","iopub.status.idle":"2025-02-25T13:17:27.819627Z","shell.execute_reply.started":"2025-02-25T13:17:27.813246Z","shell.execute_reply":"2025-02-25T13:17:27.818472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = ShakespeareDataset(words_to_ids,train_dataset)\nvalidation_dataset = ShakespeareDataset(words_to_ids,validation_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:29.036183Z","iopub.execute_input":"2025-02-25T13:17:29.036590Z","iopub.status.idle":"2025-02-25T13:17:39.179089Z","shell.execute_reply.started":"2025-02-25T13:17:29.036557Z","shell.execute_reply":"2025-02-25T13:17:39.178358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_dataset[15].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:39.180111Z","iopub.execute_input":"2025-02-25T13:17:39.180413Z","iopub.status.idle":"2025-02-25T13:17:39.195882Z","shell.execute_reply.started":"2025-02-25T13:17:39.180391Z","shell.execute_reply":"2025-02-25T13:17:39.195117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_fn(item):\n    x = torch.stack([i for i in item])\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:39.197558Z","iopub.execute_input":"2025-02-25T13:17:39.197875Z","iopub.status.idle":"2025-02-25T13:17:39.210910Z","shell.execute_reply.started":"2025-02-25T13:17:39.197848Z","shell.execute_reply":"2025-02-25T13:17:39.209989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size = 1024, collate_fn=collate_fn)\nvalid_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size = 1024, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:39.211858Z","iopub.execute_input":"2025-02-25T13:17:39.212145Z","iopub.status.idle":"2025-02-25T13:17:39.228102Z","shell.execute_reply.started":"2025-02-25T13:17:39.212119Z","shell.execute_reply":"2025-02-25T13:17:39.227225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"next(iter(train_dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T13:17:39.228959Z","iopub.execute_input":"2025-02-25T13:17:39.229223Z","iopub.status.idle":"2025-02-25T13:17:39.379138Z","shell.execute_reply.started":"2025-02-25T13:17:39.229198Z","shell.execute_reply":"2025-02-25T13:17:39.378410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LSTMModel(torch.nn.Module):\n    def __init__(self, dictionary_size, hidden_dim, layer_dim,max_seq_len):\n        super(LSTMModel, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.layer_dim = layer_dim\n        self.dropout = torch.nn.Dropout(0.3)\n        self.embedding = torch.nn.Embedding(dictionary_size,hidden_dim)\n        self.lstm = torch.nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim,num_layers=layer_dim, batch_first=True)\n        self.lin = torch.nn.Linear(hidden_dim, hidden_dim)\n        self.fc = torch.nn.Linear(hidden_dim, dictionary_size)\n\n    def forward(self, x):\n        emb = self.embedding(x)\n        out, (hn, cn) = self.lstm(emb)\n        out = self.lin(self.dropout(out))\n        predicted = self.fc(self.dropout(out)) \n        return predicted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:08:48.140225Z","iopub.execute_input":"2025-02-25T15:08:48.140540Z","iopub.status.idle":"2025-02-25T15:08:48.146422Z","shell.execute_reply.started":"2025-02-25T15:08:48.140517Z","shell.execute_reply":"2025-02-25T15:08:48.145359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dictionary_size = len(words_to_ids)+4\nhidden_dim = 200\nlayer_dim = 3\nmax_seq_len=19\nmodel = LSTMModel(dictionary_size, hidden_dim, layer_dim,max_seq_len)\nfrom functools import reduce\n\ndef get_num_of_params(\n    model : torch.nn.Module\n) -> int:\n    return sum([reduce(lambda x, y: x * y, cur.shape) for cur in model.parameters()])\n\nget_num_of_params(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:08:48.288856Z","iopub.execute_input":"2025-02-25T15:08:48.289211Z","iopub.status.idle":"2025-02-25T15:08:48.371508Z","shell.execute_reply.started":"2025-02-25T15:08:48.289184Z","shell.execute_reply":"2025-02-25T15:08:48.370752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:08:48.444710Z","iopub.execute_input":"2025-02-25T15:08:48.445093Z","iopub.status.idle":"2025-02-25T15:08:48.460395Z","shell.execute_reply.started":"2025-02-25T15:08:48.445061Z","shell.execute_reply":"2025-02-25T15:08:48.459634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:08:48.579765Z","iopub.execute_input":"2025-02-25T15:08:48.580119Z","iopub.status.idle":"2025-02-25T15:08:48.603481Z","shell.execute_reply.started":"2025-02-25T15:08:48.580090Z","shell.execute_reply":"2025-02-25T15:08:48.602765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.auto import tqdm\ntrain_loss =[]\nvalid_loss =[]\nepochs = 30\nfor epoch in tqdm(range(epochs)):\n    train_loss_current = []\n    model.train()\n    for idx, X in tqdm(enumerate(train_dataloader)):\n        preds = model(X[:,:-1].to(device))\n        loss = criterion(\n        preds.view(-1, dictionary_size), X[:,1:].to(device).contiguous().view(-1))\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()  \n        train_loss_current.append(loss.item())\n\n    train_loss.append(np.mean(train_loss_current))\n    \n    valid_loss_current = []\n    model.eval()\n    with torch.inference_mode():\n        for idx, X in enumerate(valid_dataloader):\n            preds = model(X[:,:-1].to(device))\n            loss = criterion(\n                preds.view(-1, dictionary_size), \n                X[:,1:].to(device).contiguous().view(-1)\n            )  \n            valid_loss_current.append(loss.item())\n    valid_loss.append(np.mean(valid_loss_current))\n    \n    print(f'Эпоха - {epoch+1}, train_loss - {train_loss[-1]}, valid_loss - {valid_loss[-1]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:08:49.885096Z","iopub.execute_input":"2025-02-25T15:08:49.885397Z","iopub.status.idle":"2025-02-25T15:19:27.682197Z","shell.execute_reply.started":"2025-02-25T15:08:49.885375Z","shell.execute_reply":"2025-02-25T15:19:27.681250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"f= '/kaggle/working/Shakespear.model'\ntorch.save(model.state_dict(), f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:17:22.512562Z","iopub.execute_input":"2025-02-25T14:17:22.512889Z","iopub.status.idle":"2025-02-25T14:17:22.578420Z","shell.execute_reply.started":"2025-02-25T14:17:22.512865Z","shell.execute_reply":"2025-02-25T14:17:22.577735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/shakeword/pytorch/default/1/Shakespear.model', weights_only=True,map_location=torch.device('cpu')))\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T20:47:32.010513Z","iopub.execute_input":"2025-02-24T20:47:32.010841Z","iopub.status.idle":"2025-02-24T20:47:32.569300Z","shell.execute_reply.started":"2025-02-24T20:47:32.010813Z","shell.execute_reply":"2025-02-24T20:47:32.568257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\ntr = {i+1:v for i,v in enumerate(train_loss)}\nval = {i+1:v for i,v in enumerate(valid_loss)}\n\nsns.lineplot(data=tr, label=str('Train Loss'))\nsns.lineplot(data=val, label=str('Validation Loss'))\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:56:41.045718Z","iopub.execute_input":"2025-02-25T14:56:41.046072Z","iopub.status.idle":"2025-02-25T14:56:41.239811Z","shell.execute_reply.started":"2025-02-25T14:56:41.046042Z","shell.execute_reply":"2025-02-25T14:56:41.239074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:56:43.377805Z","iopub.execute_input":"2025-02-25T14:56:43.378156Z","iopub.status.idle":"2025-02-25T14:56:43.383514Z","shell.execute_reply.started":"2025-02-25T14:56:43.378132Z","shell.execute_reply":"2025-02-25T14:56:43.382754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dec(tokens:list,dictionary:dict):\n    decoded = []\n    for i in tokens: \n        key = next((key for key, value in dictionary.items() if value == i), None)\n        decoded.append(key)\n    return decoded ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:17:32.796786Z","iopub.execute_input":"2025-02-25T14:17:32.797144Z","iopub.status.idle":"2025-02-25T14:17:32.801557Z","shell.execute_reply.started":"2025-02-25T14:17:32.797113Z","shell.execute_reply":"2025-02-25T14:17:32.800565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_SEQ_LEN = 18\ntemp=1\n@torch.inference_mode\ndef generate(tokens) -> torch.Tensor:\n    while len(tokens) < MAX_SEQ_LEN and tokens[-1]!=2:\n        tokens.append(torch.softmax(model(torch.tensor(tokens).unsqueeze(0).to(device))/temp,-1)[0][-1].argmax().item())\n        \n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:17:34.981303Z","iopub.execute_input":"2025-02-25T14:17:34.981602Z","iopub.status.idle":"2025-02-25T14:17:34.986272Z","shell.execute_reply.started":"2025-02-25T14:17:34.981579Z","shell.execute_reply":"2025-02-25T14:17:34.985273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predi(sentence):\n    final = [1]\n    sentence = tokenize_pipeline(sentence.lower())\n    try:\n        for i in range(len(sentence)):\n            final += [words_to_ids[sentence[i]]]\n        example = generate(final)\n        return ' '.join(dec(example,words_to_ids)[1:-1])\n    except:\n        print('Одного из слов в предложении Шекспир не знал...')\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:17:36.685792Z","iopub.execute_input":"2025-02-25T14:17:36.686129Z","iopub.status.idle":"2025-02-25T14:17:36.690959Z","shell.execute_reply.started":"2025-02-25T14:17:36.686104Z","shell.execute_reply":"2025-02-25T14:17:36.690016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(predi('Young and'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:06:15.975883Z","iopub.execute_input":"2025-02-24T21:06:15.976192Z","iopub.status.idle":"2025-02-24T21:06:15.997215Z","shell.execute_reply.started":"2025-02-24T21:06:15.976169Z","shell.execute_reply":"2025-02-24T21:06:15.996330Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_SEQ_LEN = 18\n@torch.inference_mode\ndef generation(tokens) -> torch.Tensor:\n    while len(tokens) < MAX_SEQ_LEN and tokens[-1]!=2:\n        preds = model(torch.tensor(tokens).unsqueeze(0).to(device))\n        preds_beam = beam_search(preds.to(device),6)[0][2]\n        last = preds_beam[-1]\n        tokens.append(last)\n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:57:10.416857Z","iopub.execute_input":"2025-02-25T14:57:10.417189Z","iopub.status.idle":"2025-02-25T14:57:10.422195Z","shell.execute_reply.started":"2025-02-25T14:57:10.417166Z","shell.execute_reply":"2025-02-25T14:57:10.421195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def beam_search(prediction, k=6):\n    batch_size, seq_length, vocab_size = prediction.shape\n    log_prob, indices = prediction[:, 0, :].topk(k, sorted=True)\n    indices = indices.unsqueeze(-1).to(device)\n    for n1 in range(1, seq_length):\n        log_prob_temp = log_prob.unsqueeze(-1) + prediction[:, n1, :].unsqueeze(1).repeat(1, k, 1)\n        log_prob, index_temp = log_prob_temp.view(batch_size, -1).topk(k, sorted=True)\n        idx_begin = index_temp // vocab_size  \n        idx_concat = index_temp % vocab_size \n        new_indices = torch.zeros((batch_size, k, n1+1), dtype=torch.int64).to(device)\n        for n2 in range(batch_size):\n            new_indices[n2, :, :-1] = indices[n2][idx_begin[n2]]\n            new_indices[n2, :, -1] = idx_concat[n2]\n        indices = new_indices\n    return indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:57:11.861339Z","iopub.execute_input":"2025-02-25T14:57:11.861645Z","iopub.status.idle":"2025-02-25T14:57:11.867546Z","shell.execute_reply.started":"2025-02-25T14:57:11.861622Z","shell.execute_reply":"2025-02-25T14:57:11.866706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predictwithbeamsearch(sentence):\n    final = [1]\n    sentence = tokenize_pipeline(sentence.lower())\n    try:\n        for i in range(len(sentence)):\n            final += [words_to_ids[sentence[i]]]\n        example = generation(final)\n        return ' '.join(dec(example,words_to_ids)[1:-1])\n    except:\n        print('Такого слова Шекспир не знал...')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:57:12.025792Z","iopub.execute_input":"2025-02-25T14:57:12.026119Z","iopub.status.idle":"2025-02-25T14:57:12.030468Z","shell.execute_reply.started":"2025-02-25T14:57:12.026091Z","shell.execute_reply":"2025-02-25T14:57:12.029679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(predictwithbeamsearch('forever'))\nprint(predictwithbeamsearch('love'))\nprint(predictwithbeamsearch('to be or not'))\nprint(predictwithbeamsearch('hi'))\nprint(predictwithbeamsearch('leave the'))\nprint(predictwithbeamsearch('poor child'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T14:57:13.954261Z","iopub.execute_input":"2025-02-25T14:57:13.954575Z","iopub.status.idle":"2025-02-25T14:57:21.295238Z","shell.execute_reply.started":"2025-02-25T14:57:13.954540Z","shell.execute_reply":"2025-02-25T14:57:21.294304Z"}},"outputs":[],"execution_count":null}]}